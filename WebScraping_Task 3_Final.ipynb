{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9c1ca-a85d-43a7-b2b6-baf66bd07fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE_URL = \"https://books.toscrape.com/\"\n",
    "res = requests.get(BASE_URL)\n",
    "soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "Categories_list_Path = soup.find(\"ul\", class_=\"nav nav-list\")\n",
    "Category_name = Categories_list_Path.find_all(\"a\")[1].text.replace(\"\\n\", \"\").strip()  # Correct index for category\n",
    "\n",
    "with open(\"books.toscrape.csv\", mode=\"w\", encoding=\"utf-8\") as fd:\n",
    "    fd.write(\"Category_Name, Book_Name, Book_Price, Book_Rating, Stock_Status\\n\")\n",
    "\n",
    "    page_len =soup.find(\"li\" , attrs= {\"class\" : \"current\"}).text.replace(\"\\n\" , \"\").replace(\"Page of \", \"\").strip()\n",
    "    \n",
    "    for page in range (page_len ):\n",
    "        \n",
    "        BASE_URL = \"https://books.toscrape.com/\"\n",
    "        res = requests.get(BASE_URL)\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "        Categories_list_Path = soup.find(\"ul\", class_=\"nav nav-list\")\n",
    "        page_number = 1\n",
    "  \n",
    "        page_url = f\"{Category_url.replace('index.html', '')}page-{page_number}.html\"\n",
    "        res_category = requests.get(page_url)\n",
    "        soup_category = BeautifulSoup(res_category.text, \"html.parser\")\n",
    "        \n",
    "        books = soup_category.find_all(\"article\", class_=\"product_pod\")\n",
    "        \n",
    "        if not books:\n",
    "            break\n",
    "\n",
    "        for book in books:\n",
    "            Book_name = book.find(\"h3\").find(\"a\").attrs['title']\n",
    "            Book_Price = book.find(\"p\", class_=\"price_color\").text\n",
    "            stock_status = book.find(\"p\", class_=\"instock availability\").text.replace(\"\\n\", \"\").strip()\n",
    "            rating = book.find(\"p\", class_=\"star-rating\")['class'][1]\n",
    "            rating_map = {\n",
    "                'One': '1 star',\n",
    "                'Two': '2 stars',\n",
    "                'Three': '3 stars',\n",
    "                'Four': '4 stars',\n",
    "                'Five': '5 stars'\n",
    "            }\n",
    "            Book_Rating = rating_map.get(rating, \"Unknown\")\n",
    "            \n",
    "            # Write data to the CSV file\n",
    "            fd.write(f\"\\\"{Category_name}\\\", \\\"{Book_name.replace(',', ' ').strip()}\\\", \\\"{Book_Price}\\\", \\\"{Book_Rating}\\\", \\\"{stock_status}\\\"\\n\")\n",
    "        \n",
    "        page_number += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e453692-8597-4f15-a797-2a1d229b2466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "UrL = \"https://books.toscrape.com\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "books = []\n",
    "\n",
    "    for book in soup.find_all('article', class_='product_pod'):\n",
    "        title = book.find('h3').find('a').get('title')\n",
    "        price = book.find('p', class_='price_color').text\n",
    "        rating = book.find('p', class_='star-rating')['class'][1]  # Gets the rating class (e.g., 'One', 'Two', etc.)\n",
    "        availability = book.find('p', class_='instock availability').text.strip()\n",
    "        \n",
    "        books.append({\n",
    "            'Title': title,\n",
    "            'Price': price,\n",
    "            'Rating': rating,\n",
    "            'Availability': availability\n",
    "        })\n",
    "    \n",
    "    return books\n",
    "\n",
    "# Function to scrape multiple pages\n",
    "def scrape_books(base_url):\n",
    "    page_number = 1\n",
    "    all_books = []\n",
    "    \n",
    "    while True:\n",
    "        url = f\"{base_url}/catalogue/page-{page_number}.html\"\n",
    "        books = fetch_page_data(url)\n",
    "        \n",
    "        if not books:\n",
    "            break\n",
    "        \n",
    "        all_books.extend(books)\n",
    "        page_number += 1\n",
    "    \n",
    "    return all_books\n",
    "\n",
    "# Base URL of the website\n",
    "base_url = \"https://books.toscrape.com\"\n",
    "\n",
    "# Scraping the books\n",
    "books_data = scrape_books(base_url)\n",
    "\n",
    "# Saving the data to a CSV file\n",
    "df = pd.DataFrame(books_data)\n",
    "df.to_csv('books_data.csv', index=False)\n",
    "\n",
    "print(f\"Scraped {len(books_data)} books.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cdbabb-849c-4837-a0c6-aac25090937f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
